{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36d16224",
   "metadata": {},
   "source": [
    "<center><h1>Movie Recommender System üìΩÔ∏èüçø<h3> by Andrew Ng </h3></h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a08ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "346debb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "\n",
    "file = open('./data/small_movies_X.csv', 'rb')\n",
    "X = loadtxt(file, delimiter = \",\")\n",
    "\n",
    "file = open('./data/small_movies_W.csv', 'rb')\n",
    "W = loadtxt(file,delimiter = \",\")\n",
    "\n",
    "file = open('./data/small_movies_b.csv', 'rb')\n",
    "\n",
    "b = loadtxt(file,delimiter = \",\")\n",
    "b = b.reshape(1,-1)\n",
    "\n",
    "num_movies, num_features = X.shape\n",
    "num_users,_ = W.shape\n",
    "\n",
    "file = open('./data/small_movies_Y.csv', 'rb')\n",
    "Y = loadtxt(file,delimiter = \",\")\n",
    "\n",
    "file = open('./data/small_movies_R.csv', 'rb')\n",
    "R = loadtxt(file,delimiter = \",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d4636d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y (4778, 443) R (4778, 443)\n",
      "X (4778, 10)\n",
      "W (443, 10)\n",
      "b (1, 443)\n",
      "num_features 10\n",
      "num_movies 4778\n",
      "num_users 443\n"
     ]
    }
   ],
   "source": [
    "print(\"Y\", Y.shape, \"R\", R.shape)\n",
    "print(\"X\", X.shape)\n",
    "print(\"W\", W.shape)\n",
    "print(\"b\", b.shape)\n",
    "print(\"num_features\", num_features)\n",
    "print(\"num_movies\",   num_movies)\n",
    "print(\"num_users\",    num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d02e708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cofi_cost_func_v(X, W, b, Y, R, lambda_):\n",
    "\n",
    "    j = (tf.linalg.matmul(X, tf.transpose(W)) + b - Y)*R\n",
    "    J = 0.5 * tf.reduce_sum(j**2) + (lambda_/2) * (tf.reduce_sum(X**2) + tf.reduce_sum(W**2))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e3a129e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New user ratings:\n",
      "\n",
      "Rated 5.0 for  28 Days Later (2002)\n",
      "Rated 3.0 for  Grudge, The (2004)\n",
      "Rated 5.0 for  Sherlock Holmes (2009)\n",
      "Rated 5.0 for  The Hunger Games (2012)\n",
      "Rated 5.0 for  Django Unchained (2012)\n",
      "Rated 4.0 for  Fantastic Beasts and Where to Find Them (2016)\n",
      "Rated 5.0 for  The Circle (2016)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "movieList_df = pd.read_csv('./data/small_movie_list.csv', header=0, index_col=0,  delimiter=',', quotechar='\"')\n",
    "movieList = movieList_df[\"title\"].to_list()\n",
    "\n",
    "my_ratings = np.zeros(num_movies)   \n",
    "\n",
    "my_ratings[4238] = 5 # the circle\n",
    "my_ratings[2575] = 5 # sherlock holmes\n",
    "my_ratings[1139] = 3 # the grudge\n",
    "my_ratings[3336] = 5 # django unchained\n",
    "my_ratings[785] = 5  # 28 days later\n",
    "my_ratings[3082] = 5 # hunger Games\n",
    "my_ratings[4089] = 4 # fantastic beasts\n",
    "\n",
    "my_rated = [i for i in range(len(my_ratings)) if my_ratings[i] > 0]\n",
    "\n",
    "print('\\nNew user ratings:\\n')\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0 :\n",
    "        print(f'Rated {my_ratings[i]} for  {movieList_df.loc[i,\"title\"]}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "144477df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload ratings and add new ratings\n",
    "file = open('./data/small_movies_Y.csv', 'rb')\n",
    "Y = loadtxt(file,delimiter = \",\")\n",
    "\n",
    "file = open('./data/small_movies_R.csv', 'rb')\n",
    "R = loadtxt(file,delimiter = \",\")\n",
    "\n",
    "\n",
    "Y    = np.c_[my_ratings, Y]\n",
    "R    = np.c_[(my_ratings != 0).astype(int), R]\n",
    "\n",
    "# Normalize the Dataset\n",
    "Ymean = (np.sum(Y*R,axis=1)/(np.sum(R, axis=1)+1e-12)).reshape(-1,1)\n",
    "Ynorm = Y - np.multiply(Ymean, R) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33f073a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Useful Values\n",
    "num_movies, num_users = Y.shape\n",
    "num_features = 100\n",
    "\n",
    "# Set Initial Parameters (W, X), use tf.Variable to track these variables\n",
    "tf.random.set_seed(1234) # for consistent results\n",
    "W = tf.Variable(tf.random.normal((num_users,  num_features),dtype=tf.float64),  name='W')\n",
    "X = tf.Variable(tf.random.normal((num_movies, num_features),dtype=tf.float64),  name='X')\n",
    "b = tf.Variable(tf.random.normal((1,          num_users),   dtype=tf.float64),  name='b')\n",
    "\n",
    "# Instantiate an optimizer.\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91478e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 2321121.9\n",
      "Training loss at iteration 20: 136160.5\n",
      "Training loss at iteration 40: 51854.1\n",
      "Training loss at iteration 60: 24594.4\n",
      "Training loss at iteration 80: 13628.2\n",
      "Training loss at iteration 100: 8486.2\n",
      "Training loss at iteration 120: 5806.5\n",
      "Training loss at iteration 140: 4310.5\n",
      "Training loss at iteration 160: 3434.2\n",
      "Training loss at iteration 180: 2900.9\n"
     ]
    }
   ],
   "source": [
    "iterations = 200\n",
    "lambda_ = 1\n",
    "for iter in range(iterations):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "\n",
    "        cost_value = cofi_cost_func_v(X, W, b, Ynorm, R, lambda_)\n",
    "\n",
    "    grads = tape.gradient( cost_value, [X,W,b] )\n",
    "\n",
    "    optimizer.apply_gradients( zip(grads, [X,W,b]) )\n",
    "\n",
    "    if iter % 20 == 0:\n",
    "        print(f\"Training loss at iteration {iter}: {cost_value:0.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4273ac0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting rating 5.87 for movie Martin Lawrence Live: Runteldat (2002)\n",
      "Predicting rating 5.86 for movie My Sassy Girl (Yeopgijeogin geunyeo) (2001)\n",
      "Predicting rating 5.85 for movie The Girl with All the Gifts (2016)\n",
      "Predicting rating 5.85 for movie Bossa Nova (2000)\n",
      "Predicting rating 5.85 for movie Dragons: Gift of the Night Fury (2011)\n",
      "Predicting rating 5.85 for movie Son of the Bride (Hijo de la novia, El) (2001)\n",
      "Predicting rating 5.85 for movie Delirium (2014)\n",
      "Predicting rating 5.85 for movie Laggies (2014)\n",
      "Predicting rating 5.85 for movie One I Love, The (2014)\n",
      "Predicting rating 5.85 for movie Rivers and Tides (2001)\n",
      "Predicting rating 5.85 for movie Ex Drummer (2007)\n",
      "Predicting rating 5.85 for movie Particle Fever (2013)\n",
      "Predicting rating 5.84 for movie 61* (2001)\n",
      "Predicting rating 5.84 for movie Eva (2011)\n",
      "Predicting rating 5.84 for movie Wonder Woman (2009)\n",
      "Predicting rating 5.84 for movie Paper Birds (P√°jaros de papel) (2010)\n",
      "Predicting rating 5.84 for movie Superman/Batman: Public Enemies (2009)\n",
      "\n",
      "\n",
      "Original vs Predicted ratings:\n",
      "\n",
      "Original 5.0, Predicted 4.97 for 28 Days Later (2002)\n",
      "Original 3.0, Predicted 3.16 for Grudge, The (2004)\n",
      "Original 5.0, Predicted 4.96 for Sherlock Holmes (2009)\n",
      "Original 5.0, Predicted 4.92 for The Hunger Games (2012)\n",
      "Original 5.0, Predicted 4.96 for Django Unchained (2012)\n",
      "Original 4.0, Predicted 4.34 for Fantastic Beasts and Where to Find Them (2016)\n",
      "Original 5.0, Predicted 4.70 for The Circle (2016)\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction using trained weights and biases\n",
    "p = np.matmul(X.numpy(), np.transpose(W.numpy())) + b.numpy()\n",
    "\n",
    "#restore the mean\n",
    "pm = p + Ymean\n",
    "my_predictions = pm[:,0]\n",
    "\n",
    "# sort predictions\n",
    "ix = tf.argsort(my_predictions, direction='DESCENDING')\n",
    "\n",
    "for i in range(17):\n",
    "    j = ix[i]\n",
    "    if j not in my_rated:\n",
    "        print(f'Predicting rating {my_predictions[j]:0.2f} for movie {movieList[j]}')\n",
    "\n",
    "print('\\n\\nOriginal vs Predicted ratings:\\n')\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0:\n",
    "        print(f'Original {my_ratings[i]}, Predicted {my_predictions[i]:0.2f} for {movieList[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a222320d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
